{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_component_tests = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from BaseClasses import triggering, eFMU, optimization_root\n",
    "\n",
    "if run_component_tests:\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "    \n",
    "    import sys\n",
    "    path_forecasting = r'D:\\Users\\emma\\Documents\\GitHub\\SmartInverter\\smartinverter_optimization'\n",
    "    sys.path.append(os.path.join(path_forecasting, 'SlowActing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ForecastMPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ComputeTariff import tariff_pge_e19\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "class mpc_input(eFMU):   \n",
    "    def __init__(self):\n",
    "        self.input = {\n",
    "            'time':None,\n",
    "            'p_pv':None,\n",
    "            'p_pv_hist':None,\n",
    "            'p_pv_hist_init':None,\n",
    "            'config':None,\n",
    "            'models':None,\n",
    "            'external_weather_forecast':False,\n",
    "            'location_latitude':None,\n",
    "            'location_longitude':None,\n",
    "            'tz_st':None,\n",
    "            'wf_prev':None,\n",
    "            'forecast_pv_prev':None,\n",
    "            'forecast_load_prev':None\n",
    "        }        \n",
    "        self.output = {\n",
    "            'generation_pv':None,\n",
    "            'load_demand':None,\n",
    "            'p_pv_hist_update':None,\n",
    "            'weather_forecast':None,\n",
    "            'forecast_pv_sarima':None,\n",
    "            'forecast_pv_nn':None,\n",
    "            'forecast_pv_next':None,\n",
    "            'forecast_pv_diff':None,\n",
    "            'forecast_pv_error':None,\n",
    "            'forecast_load_next':None,\n",
    "            'forecast_load_diff':None,\n",
    "            'forecast_load_error':None\n",
    "        } \n",
    "        self.pvforecast = None\n",
    "        from DefaultConfiguration import get_input_example2, get_input_example3\n",
    "        #self.staticinput = get_input_example2() # Flexlab load\n",
    "        self.staticinput = get_input_example3() # B90 load\n",
    "        self.init = True\n",
    "        \n",
    "    def emulate(self, now):\n",
    "        df = self.staticinput.copy(deep=True)\n",
    "        df.loc[df.index[-1]+pd.DateOffset(hours=1)] = df.iloc[0]\n",
    "        df = df.resample('1T').asfreq()\n",
    "        for c in df.columns:\n",
    "            if c in ['load_demand','generation_pv']:\n",
    "                df[c] = df[c].interpolate()\n",
    "            else:\n",
    "                df[c] = df[c].ffill()\n",
    "        ix_start = pd.to_datetime(now.strftime('%Y-%m-%d %H:%M:00'))\n",
    "        ix_df = min(df.index[(df.index.hour==ix_start.hour) & (df.index.minute==ix_start.minute)])\n",
    "        df = df.loc[ix_df::].append(df.loc[df.index[0]:ix_df])\n",
    "        df = df[~df.index.duplicated(keep='first')] \n",
    "        df = df.reset_index(drop=True)\n",
    "        df.index = [ix_start + pd.DateOffset(minutes=ix) for ix in df.index]\n",
    "        df['generation_pv'] = df['generation_pv'] * 1e3\n",
    "        df['load_demand'] = df['load_demand'] * 1e3\n",
    "        return df\n",
    "    \n",
    "    def filter_pvhist(self, pv_hist_raw):\n",
    "        pv_hist = pv_hist_raw.copy(deep=True).resample('1T').interpolate().resample('15T',base=pv_hist_raw.index[-1].minute).asfreq()\n",
    "        pv_hist = pv_hist.mask((pv_hist.index.hour<5) | (pv_hist.index.hour>20), 0) # Filter night time\n",
    "        pv_hist = pv_hist.mask(pv_hist<10, 0) # Filter negativ PV\n",
    "        pv_hist = pv_hist.mask(pv_hist.diff(1).abs()>500, np.nan) # Filter slope\n",
    "        #pv_hist = pv_hist.dropna()\n",
    "        pv_hist = pv_hist.interpolate()\n",
    "        return pv_hist\n",
    "    \n",
    "    def compute(self):\n",
    "        error = ''\n",
    "        now = (pd.to_datetime(self.input['time'], unit='s').replace(microsecond=0, nanosecond=0)+\\\n",
    "               pd.DateOffset(hours=self.input['tz_st'])).to_pydatetime()\n",
    "        #print 'NOW', datetime.now(), now\n",
    "        #print 'PV_now', self.input['p_pv']\n",
    "        ts = 5 #min Optimization and histroic data\n",
    "        ts_fc = 15 #min Forecast\n",
    "        horizon = 23 #hours\n",
    "        # Initialization\n",
    "        #print self.input['p_pv_hist']\n",
    "        if self.init and self.input['p_pv_hist_init']:\n",
    "            error += 'Assign PV History (None)\\n'\n",
    "            self.input['p_pv_hist'] = self.input['p_pv_hist_init']\n",
    "        #print len(self.input['p_pv_hist']), (60/ts_fc*horizon*2)\n",
    "        if not self.input['p_pv_hist']:\n",
    "            error += 'Initialize PV History (None)\\n'\n",
    "            ix = [now.replace(second=0, microsecond=0)-timedelta(minutes=t*ts_fc+ts_fc) for t in range(60/ts_fc*horizon*2)]\n",
    "            self.input['p_pv_hist'] = pd.Series([0.0]*(60/ts_fc*horizon*2), index=pd.to_datetime(ix))\n",
    "            self.input['p_pv_hist'].index = (self.input['p_pv_hist'].index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "            self.input['p_pv_hist'] = self.input['p_pv_hist'].to_dict()\n",
    "            warnings.warn('Initialize PV History (None)', Warning)\n",
    "        # Read PV hist_raw\n",
    "        pv_hist_raw = pd.Series(self.input['p_pv_hist'])\n",
    "        pv_hist_raw.index = pd.to_datetime(pv_hist_raw.index, unit='ms')\n",
    "        # Add current measurement\n",
    "        pv_hist_raw.loc[now.replace(second=0, microsecond=0)] = float(self.input['p_pv'])\n",
    "        #print pv_hist_raw.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        # Render pv_hist (for current timestep)\n",
    "        pv_hist = self.filter_pvhist(pv_hist_raw)\n",
    "        #pv_hist.plot()\n",
    "        #print pv_hist.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #print len(pv_hist), (60/ts_fc*horizon*2)\n",
    "        \n",
    "        if not len(pv_hist) > (60/ts_fc*horizon):\n",
    "            #print len(self.input['p_pv_hist']), (60/ts_fc*horizon*2)\n",
    "            error += 'Initialize PV History (len<len)\\n'\n",
    "            ix = [now.replace(second=0, microsecond=0)-timedelta(minutes=t*ts_fc+ts_fc) for t in range(60/ts_fc*horizon*2)]\n",
    "            self.input['p_pv_hist'] = pd.Series([0.0]*(60/ts_fc*horizon*2), index=pd.to_datetime(ix))\n",
    "            #self.input['p_pv_hist'].index = (self.input['p_pv_hist'].index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "            #self.input['p_pv_hist'] = self.input['p_pv_hist'].to_dict()\n",
    "            warnings.warn('Initialize PV History (len<len)', Warning)\n",
    "        #print 'Error', error\n",
    "        # Get inputs and update historian\n",
    "        #pv_hist = pd.Series(self.input['p_pv_hist'])\n",
    "        #pv_hist.index = pd.to_datetime(pv_hist.index, unit='ms')\n",
    "        #print pv_hist[np.isnan(pv_hist)]\n",
    "        #pv_hist.loc[now.replace(second=0, microsecond=0)] = float(self.input['p_pv'])\n",
    "        #print pv_hist.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #print pv_hist.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #pv_hist = pv_hist.iloc[-(60/ts*horizon*2)::]\n",
    "        #pv_hist = pv_hist.resample('15T', base=pv_hist.index[-1].minute).mean()\n",
    "        #print 'A', len(pv_hist)\n",
    "        #print pv_hist\n",
    "        #print pv_hist[-5::]\n",
    "        #print pv_hist.resample('1T').interpolate()[-20::]\n",
    "        #pv_hist = pv_hist.resample('1T').interpolate().resample('15T',base=pv_hist.index[-1].minute).asfreq() # Interpolate\n",
    "        #print pv_hist[-5::]\n",
    "        #print 'B', len(pv_hist)\n",
    "        #pv_hist = pv_hist.dropna()\n",
    "        #print 'C', len(pv_hist)\n",
    "        #print throwanerror\n",
    "        #print pv_hist.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        # Get PV forecast\n",
    "        if not self.pvforecast:\n",
    "            from MPCforecasting_V2 import Forecasting, get_forecast_noaa\n",
    "            models = copy.deepcopy(self.input['models'])\n",
    "            self.pvforecast = Forecasting(models=models, config=self.input['config'])\n",
    "            self.get_forecast = get_forecast_noaa\n",
    "            #print self.pvforecast.loaded_models\n",
    "        # Get weather forecast\n",
    "        #print self.input['external_weather_forecast']\n",
    "        if not isinstance(self.input['external_weather_forecast'], pd.Series):\n",
    "            if self.input['location_longitude'] > 0: print 'Warning: Longitufe is typically > 0!'\n",
    "            config = {}\n",
    "            config['location_latitude'] = self.input['location_latitude']\n",
    "            config['location_longitude'] = self.input['location_longitude']\n",
    "            config['tz_st'] = self.input['tz_st']\n",
    "            wf_prev = pd.Series(self.input['wf_prev'])\n",
    "            \n",
    "            # This section is just for testing purposes\n",
    "            timeout = 5\n",
    "            if 'test_forcast' in self.input.keys():\n",
    "                timeout = 0.001\n",
    "            # End testing purpose\n",
    "            \n",
    "            wf, tmp = self.get_forecast(now, config, wf_prev=wf_prev, timeout=timeout)\n",
    "            error += tmp\n",
    "            wf['timeIndex'] = pd.to_datetime(wf['timeIndex'])\n",
    "        else:\n",
    "            print 'ERROR!, Not implemented!'\n",
    "        #print wf\n",
    "        #print 'WARNING: Temporarly shift pv_hist by 1 hour (to PDT)!'\n",
    "        #pv_hist.index = pv_hist.index.shift(4)\n",
    "        #print pv_hist.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #print pv_hist.index        \n",
    "        pv_fc = self.pvforecast.do_forecast(pv_hist, wf)\n",
    "        #print pv_fc.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #pv_hist.plot()\n",
    "        #pv_fc.plot()\n",
    "        #print pv_fc\n",
    "        df = pd.DataFrame({}, index=pv_fc.index)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.loc[df.index[0]:(df.index[0]+pd.DateOffset(hours=24))]\n",
    "        df['generation_pv'] = pv_fc\n",
    "        #print df\n",
    "        df = df.resample('15T',base=df.index[0].minute).asfreq()\n",
    "        #print 'WARNING: Temporarly shift pv_fc by -1 hour! (to PST)'\n",
    "        #df.index = df.index.shift(-4)\n",
    "        #print df\n",
    "        df.loc[now.replace(second=0, microsecond=0), 'generation_pv'] = float(self.input['p_pv'])\n",
    "        df = df.sort_index()\n",
    "        df = df.resample('15T',base=df.index[0].minute).asfreq()\n",
    "        #print df\n",
    "        #print df.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        #df['generation_pv'].plot()\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "\n",
    "        #print df\n",
    "        #df = self.compute_periods(df, self.input['tariff'], tz_df=self.input['tz_st'], tz_local=self.input['tz_local'])\n",
    "        \n",
    "        emu = self.emulate(now)\n",
    "        df['load_demand'] = emu['load_demand'] # FIMXE\n",
    "        #df['tariff_regdn'] = emu['tariff_regdn'] # FIMXE\n",
    "        #df['tariff_regup'] = emu['tariff_regup'] # FIMXE\n",
    "        \n",
    "        # Scale PV and building load\n",
    "        df['generation_pv'] = df['generation_pv']/1e3\n",
    "        df['load_demand'] = df['load_demand']/1e3\n",
    "        if 'scale_pv' in self.input['config'].keys():\n",
    "             df['generation_pv'] = df['generation_pv'] * self.input['config']['scale_pv']\n",
    "        if 'scale_load' in self.input['config'].keys():\n",
    "             df['load_demand'] = df['load_demand'] * self.input['config']['scale_load']       \n",
    "       \n",
    "        # Output\n",
    "        self.output['forecast_pv_next'] = float(df['generation_pv'].values[1]*1e3)\n",
    "        self.output['forecast_load_next'] = float(df['load_demand'].values[1]*1e3)\n",
    "        df.index = (df.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "        df = df.round(2).to_dict()\n",
    "        for k,v in df.iteritems():\n",
    "            self.output[k] = v\n",
    "        #print self.output['generation_pv']\n",
    "        #pv_fc.index = (pv_fc.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "        #self.output['p_pv_forecast'] = pv_fc.round(10).to_dict()\n",
    "        #print pv_hist\n",
    "        #print len(pv_hist)\n",
    "        pv_hist_raw = pv_hist_raw.loc[pv_hist_raw.index[-1]-pd.DateOffset(days=2)::]\n",
    "        #print pv_hist_raw.iloc[[0,1,2,3,4,5,-5,-4,-3,-2,-1]]\n",
    "        \n",
    "        #print len(pv_hist)\n",
    "        pv_hist_raw.index = (pv_hist_raw.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "        self.output['p_pv_hist_update'] = pv_hist_raw.round(2).to_dict()\n",
    "        \n",
    "        \n",
    "        #print len(self.output['p_pv_hist_update']), (60/ts_fc*horizon*2)\n",
    "        \n",
    "        wf['timeIndex'] = time.mktime(wf['timeIndex'].timetuple())\n",
    "        self.output['weather_forecast'] = wf.to_dict()\n",
    "        forecast_pv_sarima = self.pvforecast.forecast['sarima']\n",
    "        forecast_pv_sarima.index = (forecast_pv_sarima.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "        self.output['forecast_pv_sarima'] = forecast_pv_sarima.to_dict()\n",
    "        forecast_pv_nn = self.pvforecast.forecast['nn']\n",
    "        forecast_pv_nn.index = (forecast_pv_nn.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "        self.output['forecast_pv_nn'] = forecast_pv_nn.to_dict()\n",
    "        \n",
    "        # forecast statistics\n",
    "        if not self.init:\n",
    "            self.output['forecast_pv_diff'] = float(self.input['forecast_pv_prev']) - float(self.input['p_pv'])\n",
    "            if self.input['p_pv'] <> 0:\n",
    "                self.output['forecast_pv_error'] = self.output['forecast_pv_diff'] / float(self.input['p_pv'])\n",
    "            else:\n",
    "                self.output['forecast_pv_error'] = -1\n",
    "            self.output['forecast_load_diff'] = -1\n",
    "            self.output['forecast_load_error'] = -1\n",
    "    \n",
    "        #print self.output\n",
    "        \n",
    "        self.init = False\n",
    "        error = error if len(error)>0 else 'ok'\n",
    "        return error\n",
    "        \n",
    "import pytz\n",
    "from SMAPDownload_V1 import API_FL\n",
    "from flexgrid_dictionary_V1 import get_felxgrid_smap\n",
    "\n",
    "def generate_smap_dict(smap_channels, smap_dict):\n",
    "    channels = {}\n",
    "    for c in smap_channels:\n",
    "        channels[smap_dict[c]['uuid']] = c\n",
    "    return channels  \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_PV_smap(now, readings, inv_id, tz=-8):\n",
    "    fmt = '%Y-%m-%dT%H:%M:%S'\n",
    "    smap_channels = ['DC_P_W','Batt_P_W']\n",
    "    smap_dict = readings[inv_id]['channels']\n",
    "    dst = datetime.now(pytz.timezone('US/Pacific')).timetuple().tm_isdst\n",
    "    now = (pd.to_datetime(now, unit='s').replace(microsecond=0, nanosecond=0) + \n",
    "           pd.DateOffset(hours=tz)+pd.DateOffset(hours=dst)) # Convert to local time; SMAP returns standard time\n",
    "    smap = API_FL(','.join(generate_smap_dict(smap_channels, smap_dict)),\n",
    "                  (now-timedelta(days=3)).strftime(fmt), now.to_pydatetime().strftime(fmt),\n",
    "                  'flexstorevh.lbl.gov')\n",
    "    smap = smap.rename(columns=generate_smap_dict(smap_channels, smap_dict))\n",
    "    smap['DC_P_W'] = smap['DC_P_W'].mask((smap['DC_P_W']>8600) | (smap['DC_P_W']<-8600) , np.nan)\n",
    "    smap['DC_PV_W'] = smap['DC_P_W'] + smap['Batt_P_W']\n",
    "    smap['DC_PV_W'] = smap['DC_PV_W'].mask((smap.index.hour<5) | (smap.index.hour>20), 0) # Filter night time\n",
    "    smap['DC_PV_W'] = smap['DC_PV_W'].mask(smap['DC_PV_W']<10, 0) # Filter negativ PV\n",
    "    smap['DC_PV_W'] = smap['DC_PV_W'].mask(smap['DC_PV_W'].diff(1).abs()>500, np.nan) # Filter slope\n",
    "    return smap\n",
    "    \n",
    "def warmstart_mpc_input(now, inv_id=1, tz=-8):\n",
    "    readings = get_felxgrid_smap()\n",
    "    if inv_id == 'sum':\n",
    "        p_pv_hist = pd.DataFrame()\n",
    "        for inv_id in [1,2,3]:\n",
    "            smap = get_PV_smap(now, readings, inv_id, tz=tz).resample('1T').mean()\n",
    "            if p_pv_hist.empty:\n",
    "                p_pv_hist = smap['DC_PV_W']\n",
    "            else:\n",
    "                p_pv_hist += smap['DC_PV_W']\n",
    "    else:\n",
    "        smap = get_PV_smap(now, readings, inv_id, tz=tz)\n",
    "        p_pv_hist = smap['DC_PV_W']\n",
    "    p_pv = p_pv_hist.iloc[-1]\n",
    "    p_pv_hist = p_pv_hist.drop(index=p_pv_hist.index[-1]) # Delete latest observation\n",
    "    p_pv_hist = p_pv_hist.resample('15T', base=p_pv_hist.index[-1].minute).mean().interpolate()\n",
    "    p_pv_hist = p_pv_hist.iloc[-(60/15*24*2)::]\n",
    "    p_pv_hist.index = (p_pv_hist.index.astype(np.int64) / 10 ** 6).astype(np.str)\n",
    "    p_pv_hist = p_pv_hist.to_dict()\n",
    "    return p_pv, p_pv_hist\n",
    "\n",
    "def st_to_now(st):\n",
    "    return (st - datetime(1970,1,1)).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_component_tests:\n",
    "    # get historic PV from SMAP (warm start)\n",
    "    print ('Single Inverter')\n",
    "    p_pv, p_pv_hist = warmstart_mpc_input(time.time(), inv_id=1)\n",
    "    temp = pd.Series(p_pv_hist)\n",
    "    temp.index = pd.to_datetime(temp.index, unit='ms')\n",
    "    temp.plot()\n",
    "    plt.show()\n",
    "    print ('Average of all Inverter')\n",
    "    p_pv, p_pv_hist = warmstart_mpc_input(time.time(), inv_id='sum')\n",
    "    temp = pd.Series(p_pv_hist)\n",
    "    temp.index = pd.to_datetime(temp.index, unit='ms')\n",
    "    temp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_component_tests:\n",
    "    import sys\n",
    "    # Test controller\n",
    "    dynamicforecast = mpc_input()\n",
    "    # Get all variables\n",
    "    print dynamicforecast.get_model_variables()\n",
    "\n",
    "    now = time.time()\n",
    "    tz = -8\n",
    "\n",
    "    # get historic PV from SMAP (warm start)\n",
    "    p_pv, p_pv_hist = warmstart_mpc_input(time.time())\n",
    "    temp = pd.Series(p_pv_hist)\n",
    "    temp.index = pd.to_datetime(temp.index, unit='ms')\n",
    "    temp.plot()\n",
    "\n",
    "    # Makeup some inputs\n",
    "    inputs = {'time':time.time(),'p_pv':p_pv,'p_pv_hist_init':p_pv_hist, \\\n",
    "              'location_latitude':37.87, 'location_longitude':-122.27, 'tz_st':-8}\n",
    "\n",
    "    models = {}\n",
    "    models['regression'] = {'history':4, 'prediction':2}\n",
    "    models['sarima'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/SARIMA_model_20181025.json'), \\\n",
    "                        'normPowerCoeff': 2626.0}\n",
    "    models['nn'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/NNmodel_best_20181025.sav'), \\\n",
    "                    'normPowerCoeff': 2626.0, 'normInputData':True, \\\n",
    "                    'normTa': 30.0, 'normCC': 100.0, 'normCS': 1000.0, \\\n",
    "                    'architecture':'scalar', \\\n",
    "        #                       temp  cloud sky   Pd-1  hor                    \n",
    "                    'inputData':[True, True, True, True, True],\n",
    "                    'randomSeed': 10}\n",
    "    models['alpha'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/optimal_weighting_factors_20181031.json')}\n",
    "\n",
    "    inputs['models'] = models\n",
    "    #inputs['config'] = {'pv_norm':11682}\n",
    "    inputs['config'] = {'scale_pv':1, 'scale_load':0.5}\n",
    "    inputs['p_pv_hist'] = None\n",
    "    #from MPCforecasting_V2 import example_inputs1\n",
    "    #obsDf, wfDf, PVactual, model_paths, config = example_inputs1()\n",
    "    #inputs['wf_prev'] = wfDf\n",
    "    # Query controller\n",
    "    print 'Log-message', dynamicforecast.do_step(inputs=inputs), '\\n' # Display log message\n",
    "    #print 'Output', dynamicforecast.get_output(keys=['load_demand']), '\\n'\n",
    "\n",
    "    keys = ['generation_pv','load_demand','p_pv_hist_update','forecast_pv_sarima','forecast_pv_nn']\n",
    "    out_df = dynamicforecast.get_output(keys=keys)\n",
    "    out_df = pd.DataFrame().from_dict(out_df)\n",
    "    out_df.index = pd.to_datetime(out_df.index, unit='ms')\n",
    "    print 'Historic PV:\\n', out_df['p_pv_hist_update'][~np.isnan(out_df['p_pv_hist_update'])].iloc[-3::], '\\n'\n",
    "    print 'Forecast PV:\\n', (out_df['generation_pv'][~np.isnan(out_df['generation_pv'])]*1e3).iloc[0:3], '\\n'\n",
    "    (out_df['generation_pv']*1e3).plot()\n",
    "    out_df['forecast_pv_sarima'].plot()\n",
    "    out_df['forecast_pv_nn'].plot()\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n",
    "    out_df['forecast_pv_nn'].plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if run_component_tests:\n",
    "    import sys\n",
    "    # Test controller\n",
    "    dynamicforecast = mpc_input()\n",
    "    # Get all variables\n",
    "    #print dynamicforecast.get_model_variables()\n",
    "\n",
    "    now = time.time()\n",
    "    tz = -8\n",
    "\n",
    "    # get historic PV from SMAP (warm start)\n",
    "    p_pv, p_pv_hist = warmstart_mpc_input(time.time())\n",
    "    temp = pd.Series(p_pv_hist)\n",
    "    temp.index = pd.to_datetime(temp.index, unit='ms')\n",
    "    #temp.plot()\n",
    "\n",
    "    # Makeup some inputs\n",
    "    inputs = {'time':time.time(),'p_pv':p_pv,'p_pv_hist_init':p_pv_hist, \\\n",
    "              'location_latitude':37.87, 'location_longitude':-122.27, 'tz_st':-8}\n",
    "\n",
    "    models = {}\n",
    "    models['regression'] = {'history':4, 'prediction':2}\n",
    "    models['sarima'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/SARIMA_model_20181025.json'), \\\n",
    "                        'normPowerCoeff': 2626.0}\n",
    "    models['nn'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/NNmodel_best_20181025.sav'), \\\n",
    "                    'normPowerCoeff': 2626.0, 'normInputData':True, \\\n",
    "                    'normTa': 30.0, 'normCC': 100.0, 'normCS': 1000.0, \\\n",
    "                    'architecture':'scalar', \\\n",
    "        #                       temp  cloud sky   Pd-1  hor                    \n",
    "                    'inputData':[True, True, True, True, True],\n",
    "                    'randomSeed': 10}\n",
    "    models['alpha'] = {'path':os.path.join(optimization_root,'Forecasting','models/all/20181031/optimal_weighting_factors_20181031.json')}\n",
    "\n",
    "    inputs['models'] = models\n",
    "    #inputs['config'] = {'pv_norm':11682}\n",
    "    inputs['config'] = {'scale_pv':1, 'scale_load':0.5}\n",
    "    inputs['p_pv_hist'] = None\n",
    "    inputs['forecast_pv_prev'] = 10\n",
    "    inputs['forecast_load_prev'] = 10\n",
    "    #from MPCforecasting_V2 import example_inputs1\n",
    "    #obsDf, wfDf, PVactual, model_paths, config = example_inputs1()\n",
    "    #inputs['wf_prev'] = wfDf\n",
    "    # Query controller\n",
    "    for i in range(3):\n",
    "        \n",
    "\n",
    "        if i > 0:\n",
    "            inputs['wf_prev'] = dynamicforecast.output['weather_forecast']\n",
    "            inputs['p_pv_hist'] = dynamicforecast.output['p_pv_hist_update']\n",
    "            dynamicforecast.input['test_forcast'] = 1\n",
    "        \n",
    "        \n",
    "        print 'Log-message', dynamicforecast.do_step(inputs=inputs), '\\n' # Display log message\n",
    "        #print 'Output', dynamicforecast.get_output(keys=['load_demand']), '\\n'\n",
    "\n",
    "        keys = ['generation_pv','load_demand','p_pv_hist_update','forecast_pv_sarima','forecast_pv_nn']\n",
    "        out_df = dynamicforecast.get_output(keys=keys)\n",
    "        out_df = pd.DataFrame().from_dict(out_df)\n",
    "        out_df.index = pd.to_datetime(out_df.index, unit='ms')\n",
    "        print 'Historic PV:\\n', out_df['p_pv_hist_update'][~np.isnan(out_df['p_pv_hist_update'])].iloc[-3::], '\\n'\n",
    "        print 'Forecast PV:\\n', (out_df['generation_pv'][~np.isnan(out_df['generation_pv'])]*1e3).iloc[0:3], '\\n'\n",
    "        (out_df['generation_pv']*1e3).plot()\n",
    "        out_df['forecast_pv_sarima'].plot()\n",
    "        out_df['forecast_pv_nn'].plot()\n",
    "        plt.legend(loc=2)\n",
    "        plt.show()\n",
    "\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
