{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -v statsmodels\n",
    "#!pip install -v skforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead14ff",
   "metadata": {},
   "source": [
    "### forecasters/src/fcLib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script contains a library of ML forecasters developed for the ESTCP project\n",
    "# The forecasters are designed to copy the sci-kit learn API facilitating implementation\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from scipy.stats import randint\n",
    "\n",
    "class ForecasterBase():\n",
    "    def fit(self, X=None, y=None):\n",
    "        '''\n",
    "        Implements sklearn's fit algorithm to perform the linear regression.\n",
    "        '''\n",
    "      \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X=None):\n",
    "        '''\n",
    "        Implements sklearn's predict algorithm for the supplied data set.\n",
    "        Returns the model's predictions for the supplied X values.\n",
    "        '''\n",
    "        \n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        Implements sklearn's score slgorithm for the supplied data set.\n",
    "        Returns the model's r^2 value.\n",
    "        '''\n",
    "        return self.model.score(X, y)          \n",
    "\n",
    "class extratreespipeline(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements a high-performing pipeline identified by TPOT based on sklearn's\n",
    "    ExtraTreesRegressor and PolynomialFeatures algorithms. Mimics the scikit-learn\n",
    "    API.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, **args):        \n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the pipeline\n",
    "        as an attribute to self.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        from sklearn.ensemble import ExtraTreesRegressor\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        \n",
    "        args_pf = args['polynomialfeatures']\n",
    "        args_et = args['extratrees']\n",
    "        \n",
    "        self.model = make_pipeline(\n",
    "                                   PolynomialFeatures(**args_pf),\n",
    "                                   ExtraTreesRegressor(**args_et)\n",
    "                                  )   \n",
    "\n",
    "class randomforestpipeline(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements a high-performing pipeline identified by TPOT based on sklearn's\n",
    "    RandomForestRegressor and PolynomialFeatures algorithms. Mimics the scikit-learn\n",
    "    API.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''    \n",
    "        \n",
    "    def __init__(self, **args):\n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the pipeline\n",
    "        as an attribute to self. The default values match the outputs from a TPOT\n",
    "        optimization.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.preprocessing import PolynomialFeatures, RobustScaler\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        \n",
    "        args_pf = args['polynomialfeatures']\n",
    "        args_rs = args['robustscaler']\n",
    "        args_rf = args['randomforest']             \n",
    "        \n",
    "        self.model = make_pipeline(\n",
    "                                   PolynomialFeatures(**args_pf),\n",
    "                                   RobustScaler(**args_rs),\n",
    "                                   RandomForestRegressor(**args_rf)\n",
    "                                  )\n",
    "\n",
    "class mlpregressor(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements scikit-learn's MLP regressor algorithm. Currently uses scikit-learn's \n",
    "    default parameters as the default parameters in this implementation.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''    \n",
    "        \n",
    "    def __init__(self, **args):\n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the model\n",
    "        as an attribute to self.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        from warnings import simplefilter\n",
    "        from sklearn.exceptions import ConvergenceWarning\n",
    "        \n",
    "        simplefilter('ignore', category = ConvergenceWarning)\n",
    "        \n",
    "        \n",
    "        self.model = MLPRegressor(**args)\n",
    "        self.search_parameters = {\n",
    "                                  'grid_small': {\n",
    "                                                 'hidden_layer_sizes': [100, 300, 600],\n",
    "                                                 'max_iter': [200, 400, 600],\n",
    "                                                 'momentum': [0.1, 0.5, 0.9]\n",
    "                                                },\n",
    "                                  'grid_large': {\n",
    "                                                 'hidden_layer_sizes': [100, 300, 600],\n",
    "                                                 'alpha': [0.00005, 0.0001, 0.0002],\n",
    "                                                 'max_iter': [200, 300, 500, 700],\n",
    "                                                 'momentum': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "                                                 'learning_rate_init': [0.0001, 0.001, 0.01]\n",
    "                                                },                     \n",
    "                                  'randomized': {\n",
    "                                                 'hidden_layer_sizes': randint(50, 600),\n",
    "                                                 'alpha': sp_rand(),\n",
    "                                                 'max_iter': randint(1000, 5000),\n",
    "                                                 'momentum': sp_rand()\n",
    "                                                }\n",
    "                                 }                     \n",
    "    \n",
    "class randomforest(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements scikit-learn's RandomForestRegressor algorithm. Currently uses scikit-learn's \n",
    "    default parameters as the default parameters in this implementation.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''    \n",
    "        \n",
    "    def __init__(self, **args):\n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the model\n",
    "        as an attribute to self.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "        self.model = RandomForestRegressor(**args)\n",
    "        self.search_parameters = {\n",
    "                                  'grid_small': {\n",
    "                                                 'n_estimators': [50, 200, 600],\n",
    "                                                 'min_samples_split': [2, 4, 6, 8],\n",
    "                                                 'max_features': [1, 2, 4, 6, 8]\n",
    "                                                },\n",
    "                                  'grid_large': {\n",
    "                                                 'n_estimators': [50, 100, 200, 300, 400, 500, 600],\n",
    "                                                 'min_samples_split': [2, 4, 6, 8],\n",
    "                                                 'min_samples_leaf': [1, 3, 5, 7, 9],\n",
    "                                                 'max_features': [1, 2, 4, 6, 8],\n",
    "                                                 'min_weight_fraction_leaf': [0.0, 0.2, 0.4, 0.6, 0.8]                                      \n",
    "                                                },                     \n",
    "                                  'randomized': {\n",
    "                                                 'n_estimators': randint(50, 600),\n",
    "                                                 'min_samples_split': randint(2, 6),\n",
    "                                                 'min_samples_leaf': randint(1, 5),\n",
    "                                                 'max_features': randint(2, 8)\n",
    "                                                }\n",
    "                                 }\n",
    "    \n",
    "class extratrees(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements scikit-learn's ExtraTreesRegressor algorithm. Currently uses scikit-learn's \n",
    "    default parameters as the default parameters in this implementation.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''    \n",
    "        \n",
    "    def __init__(self, **args):\n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the model\n",
    "        as an attribute to self.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.ensemble import ExtraTreesRegressor\n",
    "        \n",
    "        self.model = ExtraTreesRegressor(**args)  \n",
    "        self.search_parameters = {\n",
    "                                  'grid_small': {\n",
    "                                                 'n_estimators': [50, 200, 600],\n",
    "                                                 'min_samples_split': [2, 4, 6, 8],\n",
    "                                                 'max_features': [1, 2, 4, 6, 8],\n",
    "                                                },\n",
    "                                  'grid_large': {\n",
    "                                                 'n_estimators': [50, 100, 200, 300, 400, 500, 600],\n",
    "                                                 'min_samples_split': [2, 4, 6, 8],\n",
    "                                                 'min_samples_leaf': [1, 3, 5, 7, 9],\n",
    "                                                 'max_features': [1, 2, 4, 6, 8],\n",
    "                                                 'min_weight_fraction_leaf': [0.0, 0.2, 0.4, 0.6, 0.8]                                \n",
    "                                                },                     \n",
    "                                'randomized': {\n",
    "                                               'n_estimators': randint(50, 600),\n",
    "                                               'min_samples_split': randint(2, 6),\n",
    "                                               'min_samples_leaf': randint(1, 5),\n",
    "                                               'max_features': randint(2, 8)\n",
    "                                              }\n",
    "                               }                                 \n",
    "\n",
    "class gradientboosting(ForecasterBase, BaseEstimator):\n",
    "    '''\n",
    "    Implements scikit-learn's GradientBoostingRegressor algorithm. Currently uses \n",
    "    scikit-learn's default parameters as the default parameters in this implementation.\n",
    "    \n",
    "    Uses scikit-learn's MultiOutputRegressor to convert a single target forecaster into\n",
    "    a multiple targer forecaster. Cannot be used on single target datasets.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    '''\n",
    "           \n",
    "    def __init__(self, **args):\n",
    "        \n",
    "        '''\n",
    "        Initializes the class, loads the sklearn packages, stores the model\n",
    "        as an attribute to self.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.multioutput import MultiOutputRegressor\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        \n",
    "        # Determine if multi-target or single target\n",
    "        # Default to multi-target if not specified\n",
    "        if 'targets' not in args:\n",
    "            targets = 'multiple'\n",
    "        else:\n",
    "            targets = args.pop('targets')\n",
    "        \n",
    "        if targets == 'multiple':\n",
    "            self.model = MultiOutputRegressor(GradientBoostingRegressor(**args['GBR']),\n",
    "                                              **args['MultiOutputRegressor'])\n",
    "\n",
    "            self.search_parameters = {\n",
    "                                      'grid_small': {\n",
    "                                                     'estimator__n_estimators': [50, 200, 350],\n",
    "                                                     'estimator__max_depth': [1, 5],\n",
    "                                                    },\n",
    "                                      'grid_large': {\n",
    "                                                     'estimator__n_estimators': [50, 100, 200, 300, 400, 500, 600],\n",
    "                                                     'estimator__min_samples_split': [2, 4, 6, 8],\n",
    "                                                     'estimator__min_samples_leaf': [1, 3, 5, 7, 9],\n",
    "                                                     'estimator__max_depth': [1, 2, 3, 4, 5],\n",
    "                                                     'estimator__max_features': [1, 2, 4, 6, 8],\n",
    "                                                     'estimator__min_weight_fraction_leaf': [0.0, 0.2, 0.4, 0.6, 0.8]                                \n",
    "                                                    },                     \n",
    "                                    'randomized': {\n",
    "                                                   'estimator__n_estimators': randint(50, 600),\n",
    "                                                   'estimator__min_samples_split': randint(2, 6),\n",
    "                                                   'estimator__min_samples_leaf': randint(1, 5),\n",
    "                                                   'estimator__max_depth': randint(1, 5),\n",
    "                                                   'estimator__max_features': randint(2, 8)\n",
    "                                                  }\n",
    "                                   }         \n",
    "        elif targets == 'single':\n",
    "            self.model = GradientBoostingRegressor(**args['GBR'])\n",
    "            self.search_parameters = {\n",
    "                                      'grid_small': {\n",
    "                                                     'n_estimators': [50, 100, 200, 400, 600],\n",
    "                                                     'min_samples_split': [2, 4, 6, 8],\n",
    "                                                     'min_samples_leaf': [1, 3, 5, 7],\n",
    "                                                     'max_depth': [1, 2, 3],\n",
    "                                                     'max_features': [1, 2, 4, 6, 8]\n",
    "                                                    },\n",
    "                                      'grid_large': {\n",
    "                                                     'n_estimators': [50, 100, 200, 300, 400, 500, 600],\n",
    "                                                     'min_samples_split': [2, 4, 6, 8],\n",
    "                                                     'min_samples_leaf': [1, 3, 5, 7, 9],\n",
    "                                                     'max_depth': [1, 2, 3, 4, 5],\n",
    "                                                     'max_features': [1, 2, 4, 6, 8],\n",
    "                                                     'min_weight_fraction_leaf': [0.0, 0.2, 0.4, 0.6, 0.8]                                \n",
    "                                                    },                     \n",
    "                                     'randomized': {\n",
    "                                                    'n_estimators': randint(50, 600),\n",
    "                                                    'min_samples_split': randint(2, 6),\n",
    "                                                    'min_samples_leaf': randint(1, 5),\n",
    "                                                    'max_depth': randint(1, 5),\n",
    "                                                    'max_features': randint(2, 8)\n",
    "                                                   }  \n",
    "                                      } \n",
    "\n",
    "class sarimax_with_forecast(BaseEstimator):\n",
    "    '''\n",
    "    An implementation of statsmodels SARIMAX function. Currently uses primarily default\n",
    "    inputs with order, seasonal_order, and trend being adjusted to yield better results.\n",
    "    \n",
    "    Note: The base SARIMAX model is not compatible with numpy 1.24. Downgrading to numpy 1.23\n",
    "    will resolve the issue.\n",
    "    \n",
    "    methods:\n",
    "    __init__: Initializes the class, loads the sklearn packages, stores the model\n",
    "              as an attribute to self.\n",
    "    fit: Fits the model using the provided data.\n",
    "    predict: Uses the model to predict the values for the input\n",
    "             X data. Returns the predictions.\n",
    "    score: Calculates and returns the r^2 value for the supplied data set.   \n",
    "    \n",
    "    Some parameters are renamed to match scikit-learn API. For instance, 'endog' in\n",
    "    statsmodels terminology is y in scikit-learn, and y here. 'exog' is changed to 'X'.\n",
    "    '''\n",
    "        \n",
    "    def __init__(self, order_1, order_2, order_3, seasonal_order_1, seasonal_order_2, seasonal_order_3,\n",
    "                       seasonal_order_4, trend, full_output, callback, return_params, X_column_categories):\n",
    "        \n",
    "        '''\n",
    "        Reads the parameters and stores them as attributes to self so that they can later be\n",
    "        referenced and used by the other functions. To match scikit-learn API and provide a\n",
    "        consistent interface all parameters are set when initializing, and not set when\n",
    "        calling independent functions.\n",
    "        '''\n",
    "\n",
    "        import random\n",
    "        \n",
    "        self.search_parameters = {\n",
    "                                  'grid_small': {\n",
    "                                                 'order_1': [1, 2, 3],\n",
    "                                                 'order_2': [0, 1],\n",
    "                                                 'order_3': [0, 1],\n",
    "                                                 'seasonal_order_1': [0],\n",
    "                                                 'seasonal_order_2': [1],\n",
    "                                                 'seasonal_order_3': [1],\n",
    "                                                 'seasonal_order_4': [4, 5],\n",
    "                                                },\n",
    "                                  'grid_large': {\n",
    "                                                 'order_1': [1, 2, 3],\n",
    "                                                 'order_2': [0, 1, 2],\n",
    "                                                 'order_3': [0, 1, 2],\n",
    "                                                 'seasonal_order_1': [0],\n",
    "                                                 'seasonal_order_2': [1],\n",
    "                                                 'seasonal_order_3': [1, 2],\n",
    "                                                 'seasonal_order_4': [4, 5],\n",
    "                                                 'trend': [None, 'n', 'c', 't', 'ct'],\n",
    "                                               },\n",
    "                                  'randomized': {\n",
    "                                                 'order_1': randint(0, 4),\n",
    "                                                 'order_2': randint(0, 4),\n",
    "                                                 'order_3': randint(0, 4),\n",
    "                                                 'seasonal_order_1': randint(0, 12),\n",
    "                                                 'seasonal_order_2': randint(0, 12),\n",
    "                                                 'seasonal_order_3': randint(0, 12),\n",
    "                                                 'seasonal_order_4': randint(0, 12),\n",
    "                                                 'trend': [None, 'n', 'c', 't', 'ct'],\n",
    "                                                }\n",
    "                                  }                      \n",
    "\n",
    "\n",
    "        self.order_1 = order_1\n",
    "        self.order_2 = order_2\n",
    "        self.order_3 = order_3\n",
    "        self.seasonal_order_1 = seasonal_order_1\n",
    "        self.seasonal_order_2 = seasonal_order_2\n",
    "        self.seasonal_order_3 = seasonal_order_3\n",
    "        self.seasonal_order_4 = seasonal_order_4\n",
    "        self.trend = trend\n",
    "        self.full_output = full_output\n",
    "        self.callback = callback\n",
    "        self.return_params = return_params\n",
    "        self.X_column_categories = X_column_categories\n",
    "\n",
    "    def fit(self, X, y, return_summary=False, debug=False):\n",
    "        '''\n",
    "        Calls the SARIMA .fit() function to fit the model to the provided data set,\n",
    "        given the provided parameters. Stores the parameters in self.res_params.\n",
    "\n",
    "        Inputs:\n",
    "        X: The features data set.\n",
    "        y: The targets data set.\n",
    "        \n",
    "        return_summary: .fit() can return a summary of the parameters describing the model if desired.\n",
    "                        if return_summary == True this function will return that information. If not\n",
    "                        there will be no output.\n",
    "        debug: print additonal outputs.\n",
    "        \n",
    "        Outputs:\n",
    "        fit_res.summary (Optional): A summary table describing the model fit parameters. Only returned\n",
    "                                    if return_summary == True.\n",
    "        '''        \n",
    "        \n",
    "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "        import warnings\n",
    "        from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "        \n",
    "        warnings.simplefilter('ignore')\n",
    "        \n",
    "        self.prediction_columns = len(y.columns)\n",
    "        \n",
    "        cols = []\n",
    "        X = X.copy(deep = True)\n",
    "        for category in self.X_column_categories:\n",
    "            cols_category = [col for col in X.columns if col.startswith(category)]\n",
    "            if len(cols_category) > 1:\n",
    "                cols.append(cols_category[0])\n",
    "            else:\n",
    "                cols.append(cols_category)\n",
    "        X = X[cols].values     \n",
    "\n",
    "        self.model = SARIMAX(y[y.columns[0]], exog = X, order = (self.order_1, self.order_2, self.order_3), \n",
    "                             seasonal_order = (self.seasonal_order_1, self.seasonal_order_2, self.seasonal_order_3, \n",
    "                                               self.seasonal_order_4), trend = self.trend)\n",
    "\n",
    "        fit_res = self.model.fit(full_output = self.full_output, callback = self.callback, \n",
    "                                 return_params = self.return_params, disp=int(debug))\n",
    "\n",
    "        self.res_params = fit_res.params\n",
    "        \n",
    "        if return_summary:\n",
    "            return fit_res.summary()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Returns the predicted y values for the provided X data set.\n",
    "        \n",
    "        Inputs:\n",
    "        X: Dataframe of X data for which the model fit is to be tested.\n",
    "        \n",
    "        Outputs:\n",
    "        Returns predicted y values for the provided X data set.\n",
    "        '''\n",
    "\n",
    "        cols = []\n",
    "        X = X.copy(deep = True)\n",
    "        for category in self.X_column_categories:\n",
    "\n",
    "            cols_category = [col for col in X.columns if col.startswith(category)]\n",
    "\n",
    "            forecast_length_difference = self.prediction_columns - len(cols_category)\n",
    "            if forecast_length_difference > 0:\n",
    "                for i in range(1, forecast_length_difference + 1):\n",
    "\n",
    "                    col = '{}_Add_{}'.format(category, i)\n",
    "\n",
    "                    X[col] = X[cols_category[-1]]\n",
    "\n",
    "                    cols_category.append(col)\n",
    "\n",
    "            cols.extend(cols_category)\n",
    "\n",
    "        X = X[cols]\n",
    "        \n",
    "        result = pd.DataFrame(columns = range(self.prediction_columns))\n",
    "\n",
    "        for row in X.index:\n",
    "\n",
    "            X_pred = pd.DataFrame()\n",
    "            for category in self.X_column_categories:\n",
    "\n",
    "                cols_category = [col for col in X.columns if col.startswith(category)]\n",
    "\n",
    "                    \n",
    "                X_pred[cols_category[0]] = X.loc[row, cols_category].T.values\n",
    "\n",
    "            ix = pd.Series(index = range(0, len(cols_category)), dtype = 'object')\n",
    "            ix[0] = row\n",
    "            ix[1:] = ix[0] + pd.to_timedelta(ix.index[1:], unit = 'hours')\n",
    "            X_pred.index = ix\n",
    "            \n",
    "            prediction_horizon = len(X_pred.index)\n",
    "            X_pred = X_pred.astype(float)\n",
    "\n",
    "            res = self.model.filter(self.res_params)\n",
    "            predict = res.forecast(steps=prediction_horizon, exog = X_pred.values).T\n",
    "\n",
    "            result.loc[row] = predict.values.T\n",
    "\n",
    "        return result.values\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        Calculates the r^2 value of the model given the provided X and y data.\n",
    "        Predicts the resulting values over the period, compares them to\n",
    "        the provided y data, calculates and returns the r^2 coefficient.\n",
    "        \n",
    "        Inputs:\n",
    "        X: A data series or dataframe containing exogynous data for the model.\n",
    "        y: The measured values over the specified period.\n",
    "        \n",
    "        Outputs:\n",
    "        Returns the r^2 value measuring quality of fit for the model over the\n",
    "               provided data set.\n",
    "        '''\n",
    "\n",
    "        import numpy as np\n",
    "        \n",
    "        predicted = self.predict(X)\n",
    "       \n",
    "        score = r2_score(y, predicted)\n",
    "        \n",
    "        return(score)     \n",
    "    \n",
    "class time_of_day_temperature():\n",
    "    \"\"\"\n",
    "    Implement's Rongxin's regression model. Creates a LinearRegression model driven\n",
    "    by outdoor air temperature for each hour of the day. Must be able to identify\n",
    "    the columns containing outdoor air temperature, building power, and hour of the\n",
    "    day, which are specified in the parameters dictionary.\n",
    "    \n",
    "    methods:\n",
    "    fit: Iteratively fits a linear regression model to the data set for each\n",
    "         hour of the day. Stores the parameters in a dataframe for later use\n",
    "         predicting.\n",
    "    predict: Iteratively predicts the building's power consumption for each\n",
    "             hour of the day. References the dataframe of parameters stored\n",
    "             when fitting.\n",
    "    score: Calculates the r2 value of the model by comparing predictions\n",
    "           to the provided real y data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, **args):\n",
    "        '''\n",
    "        Initializes the model by reading the parameters from the args dictionary.\n",
    "        The required arguments are described in the inputs.\n",
    "        \n",
    "        Inputs:\n",
    "        oat_col: The name of the dataframe column containing ambient air temperature\n",
    "                 data.\n",
    "        power_col: The name of the dataframe column containing the building's electric\n",
    "                   power consumption data.\n",
    "        '''\n",
    "        \n",
    "        self.args = args        \n",
    "        self.intercept = pd.DataFrame()\n",
    "        self.slope = pd.DataFrame()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Iteratively creates a linear regression model for each hour of the day and stores\n",
    "        the coefficients for that model in a dataframe.\n",
    "        \n",
    "        Inputs:\n",
    "        X : The features data set.\n",
    "        y: The targets data set.\n",
    "        \"\"\"\n",
    "\n",
    "        import numpy as np\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        self.prediction_columns = len(y.columns)\n",
    "        \n",
    "        X = X.copy(deep = True)\n",
    "        X['hour'] = X.index.hour\n",
    "        cols = [col for col in X.columns if self.args['oat_col_identifier'] in col]\n",
    "\n",
    "        forecast_length_difference = self.prediction_columns - len(cols)\n",
    "        if forecast_length_difference > 0:\n",
    "            for i in range(1, forecast_length_difference+1):\n",
    "                \n",
    "                col = '{}_Add_{}'.format(todt['parameter']['oat_col_identifier'], i)\n",
    "                X[col] = X[cols[-1]] \n",
    "                cols.append(col)\n",
    "        \n",
    "        cols.append('hour')\n",
    "        X = X[cols]\n",
    "         \n",
    "        empty = []\n",
    "        hours = np.unique(X['hour'])\n",
    "\n",
    "        for hour in hours:\n",
    "    \n",
    "            X_hr = X.loc[(X.index.hour == hour)]\n",
    "            y_hr = y.loc[y.index.hour == hour]\n",
    "\n",
    "            for ix in range(X_hr.shape[1]):\n",
    "                if X_hr.columns[ix] == 'hour':\n",
    "                    continue\n",
    "                \n",
    "                X_temp = X_hr[[X_hr.columns[ix], 'hour']]\n",
    "                y_temp = y_hr[[y_hr.columns[ix]]]\n",
    "                \n",
    "                if len(X_hr.index) == 0:\n",
    "                    empty.append(hour)\n",
    "                    self.intercept.loc[hour] = 0\n",
    "                    self.slope.loc[hour] = 0\n",
    "                elif len(y_hr.index) == 0:\n",
    "                    empty.append(hour)\n",
    "                    self.intercept.loc[hour] = 0\n",
    "                    self.slope.loc[hour] = 0\n",
    "                else:\n",
    "                    model = LinearRegression()\n",
    "                    model.fit(X_temp, y_temp)\n",
    "                    self.intercept.loc[hour, ix] = model.intercept_[0]\n",
    "                    self.slope.loc[hour, ix] = model.coef_[0][0]\n",
    "        if len(empty) > 0:\n",
    "            print('WANRING: No data for hours {}'.format(empty)) \n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predicts the system response for the given X data. Returns the values\n",
    "        predicted for the given data set.\n",
    "        \n",
    "        Inputs:\n",
    "        X: The features data set for which predictions are desired.\n",
    "        \n",
    "        Outputs:\n",
    "        Returns the values predicted for the given X data set.\n",
    "        '''\n",
    "\n",
    "        result = pd.DataFrame(index = X.index)\n",
    "                    \n",
    "        X = X.copy(deep = True)\n",
    "        cols = [col for col in X.columns if self.args['oat_col_identifier'] in col]\n",
    "        X = X[cols]\n",
    "        forecast_length_difference = self.prediction_columns - len(cols)\n",
    "        if forecast_length_difference > 0:\n",
    "            for i in range(1, forecast_length_difference+1):\n",
    "                \n",
    "                col = '{}_Add_{}'.format(todt['parameter']['oat_col_identifier'], i)\n",
    "                X[col] = X[cols[-1]]            \n",
    "                \n",
    "        X['hour'] = X.index.hour\n",
    "\n",
    "        result = pd.DataFrame(index = X.index)\n",
    "        \n",
    "        for row in X.index:\n",
    "    \n",
    "            hour = row.hour\n",
    "    \n",
    "            for col in range(X.shape[1]):\n",
    "                if X.columns[col] == 'hour':\n",
    "                    continue\n",
    "                \n",
    "                b = self.intercept.loc[hour, col]\n",
    "                m = self.slope.loc[hour, col]\n",
    "                prediction = b + m * X.loc[row, X.columns[col]]\n",
    "\n",
    "                result.loc[row, col] = prediction\n",
    "\n",
    "        return(result.values)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        Returns the r2 value comparing the predictions for the given X data set to\n",
    "        the provided y data set.\n",
    "        \n",
    "        Inputs:\n",
    "        X: The features data set.\n",
    "        y: The corresponding target data set.\n",
    "        '''\n",
    "        \n",
    "        pred = self.predict(X)\n",
    "\n",
    "        score = r2_score(y, pred)\n",
    "        \n",
    "        return score\n",
    "\n",
    "class forecasters():\n",
    "    '''\n",
    "    This class provides storage and utility functions for the available forecasters.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, forecaster_list):\n",
    "        '''\n",
    "        Initializes the class to contain data on the forecasters. Requires two inputs and stores\n",
    "        the data as attributes\n",
    "        \n",
    "        Inputs:\n",
    "        forecaster_list: A list of data about each forecaster. Each entry in the list must\n",
    "                         be a dictionary following the structure used in this library. See the code\n",
    "                         for more information.\n",
    "        models: A dictionary of the available forecasters with their associated parameters. The forecasters\n",
    "                are typically initialized using the parameters specified in forecaster_list.\n",
    "        '''\n",
    "        \n",
    "        import random\n",
    "        from scipy.stats import uniform as sp_rand\n",
    "        from scipy.stats import randint\n",
    "        \n",
    "        self.forecasters = forecaster_list\n",
    "    \n",
    "    def format_output(self, forecaster, search):\n",
    "        '''\n",
    "        Extracts the results from the hyperparameter tuning process for each forecaster. Identifies and\n",
    "        returns the score and parameters of the best performing algorithm. Amends the parameter structure\n",
    "        of forecasters as required.\n",
    "        \n",
    "        Inputs:\n",
    "        forecaster: The name of the forecaster, expressed using the 'fun' parameter from forecaster_list.\n",
    "        search: The scikit-learn search object storing the score and parameters for each iteration.\n",
    "        \n",
    "        Outputs:\n",
    "        score: The calculated score of the best performing hyperparameter set for that forecaster.\n",
    "        parameters: The parameters of the best performing iteration, formatted as necessary.\n",
    "        '''\n",
    "        \n",
    "        import pandas as pd\n",
    "\n",
    "        score = search.best_score_\n",
    "        score = np.sqrt(-score)\n",
    "        parameters = search.best_params_\n",
    "\n",
    "        if forecaster['fun'] == 'gradientboosting':\n",
    "            temp = {}\n",
    "            for key in parameters.keys():\n",
    "                new_key = key.replace('estimator__', '')\n",
    "                temp[new_key] = parameters[key]\n",
    "            parameters = {\n",
    "                          'MultiOutputRegressor': {},\n",
    "                          'GBR': temp\n",
    "                         }\n",
    "        elif forecaster['fun'] == 'sarimax_with_forecast':\n",
    "            parameters['full_output'] = forecaster['parameter']['full_output']\n",
    "            parameters['callback'] = forecaster['parameter']['callback']\n",
    "            parameters['return_params'] = forecaster['parameter']['return_params']\n",
    "            parameters['trend'] = forecaster['parameter']['trend']\n",
    "            parameters['X_column_categories'] = forecaster['parameter']['X_column_categories']\n",
    "\n",
    "        return score, parameters\n",
    "    \n",
    "    def tune_hyperparameters(self, X, y, method='grid_small', cv=None, n_forecasters=5,\n",
    "                             n_jobs=None, n_iter=100, random_state=42):\n",
    "        '''\n",
    "        Calls the scikit-learn GridSearchCV or RandomizedSearchCV function to tune the hyperparameters of\n",
    "        the forecasters in the library. This algorithm will only perform optimization on forecasters that\n",
    "        include the 'search_parameters' attribute. Stores a list of tuned_forecasters un the class\n",
    "        enabling use of the tuned forecasters in the future.\n",
    "        \n",
    "        Inputs:\n",
    "        X: The X data set to be used in hyperparameter tuning.\n",
    "        y: The y data set to be used in hyperparameter tuning.\n",
    "        method: The search method to be used. Options are 'grid_small', 'grid_large' and 'randomized'.\n",
    "        cv (optional): The number of folds to use when performing cross-validation.\n",
    "        n_forecsters (optional): The number of tunable forecasters to include when returning the best\n",
    "                      performing models.\n",
    "        n_jobs (optional): The number of cores to use when performing the hyperparameter tuning.\n",
    "        n_iter (optional): The number of iterations to use when performing randomized search.\n",
    "        random_state (optional): The random state to use when perfoming randomized search.\n",
    "        '''\n",
    "        \n",
    "        from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "        import sys\n",
    "    \n",
    "        result = pd.DataFrame(columns = ['score', 'forecaster', 'parameters'])\n",
    "    \n",
    "        i = 0\n",
    "        \n",
    "        self.tuned_forecasters = []\n",
    "        \n",
    "        completed = []\n",
    "        \n",
    "        for forecaster in self.forecasters:\n",
    "            \n",
    "            model = getattr(sys.modules[__name__], forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "            if not hasattr(model, 'search_parameters'):\n",
    "                continue\n",
    "                \n",
    "            elif forecaster['fun'] in completed:\n",
    "                continue\n",
    "\n",
    "            model_params = model.search_parameters[method]                \n",
    "                \n",
    "            if forecaster['fun'] != 'sarimax_with_forecast':\n",
    "                model = model.model\n",
    "                \n",
    "            scoring = 'neg_mean_squared_error'\n",
    "\n",
    "            if 'grid' in method:\n",
    "                search = GridSearchCV(model, model_params, cv = cv, scoring = scoring, n_jobs = n_jobs, \n",
    "                                      return_train_score = True)\n",
    "                search.fit(X, y)\n",
    "                    \n",
    "            elif method == 'randomized':\n",
    "                search = RandomizedSearchCV(model, model_params, n_iter = n_iter, cv = cv, scoring = scoring, \n",
    "                                            n_jobs = n_jobs, random_state = random_state)\n",
    "                search.fit(X, y)\n",
    "            else:\n",
    "                sys.exit('ERROR: method {} not supported.')\n",
    "\n",
    "            score, parameters = self.format_output(forecaster, search)\n",
    "\n",
    "            result.loc[i, 'score'] = score\n",
    "            result.loc[i, 'forecaster'] = forecaster['fun']\n",
    "            result.loc[i, 'parameters'] = [parameters]\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "            completed.append(forecaster['fun'])\n",
    "    \n",
    "        result['score'] = pd.to_numeric(result['score'])\n",
    "        result = result.nsmallest(n_forecasters, 'score')\n",
    "        \n",
    "        for row in result.index:\n",
    "            forecaster = result.loc[row, 'forecaster']\n",
    "            parameters = result.loc[row, 'parameters'][0]   \n",
    "            temp = {\n",
    "                    'name': '{}_autotuned'.format(forecaster),\n",
    "                    'fun': forecaster,\n",
    "                    'parameter': parameters,\n",
    "                    'description': '{} with hyperparameters tuned using self.tune_forecasters()'.format(forecaster)\n",
    "                   }\n",
    "            self.tuned_forecasters.append(temp)\n",
    "        \n",
    "# The following dictionaries contain information about and default parameters for the\n",
    "# forecasters in this library\n",
    "# 'name' states the name of the forecaster\n",
    "# 'fun' provides the name of the function\n",
    "# 'parameter' provides the parameters for the forecaster. Depending on the needs of the \n",
    "# forecaster they are often nested dictionaries. The values provided in the dictionaries\n",
    "# are typically the default values for the forecaster tools. In some specific cases, such\n",
    "# as time of week temperature they are the values needed to use the test data set\n",
    "# 'requires_forecast' states whether or not a weather forecast is mandatory for\n",
    "# using the forecaster\n",
    "# 'description' provides a short description of the forecaster and how it functions\n",
    "    \n",
    "    \n",
    "extra_trees_pipeline = {\n",
    "                        'name': 'extra_trees_pipeline',\n",
    "                        'fun': 'extratreespipeline',\n",
    "                        'parameter': {\n",
    "                                      'polynomialfeatures': {\n",
    "                                                             'include_bias': False\n",
    "                                                            },\n",
    "                                      'extratrees': {\n",
    "                                                     'min_samples_split': 6,\n",
    "                                                     'min_samples_leaf': 2,\n",
    "                                                     'max_features': 0.4\n",
    "                                                    }\n",
    "                                     },\n",
    "                        'requires_forecast': True,\n",
    "                        'description': '''scikit-learn ExtraTreesRegressor pipeline as recommended by TPOT. \n",
    "                                       Pre-processes the data with scikit-learn's PolynomialFeatures. \n",
    "                                       Default values as recommended by TPOT.'''\n",
    "                       }\n",
    "random_forest_pipeline = {\n",
    "                          'name': 'random_forest_pipeline',\n",
    "                          'fun': 'randomforestpipeline',\n",
    "                          'parameter': {\n",
    "                                        'polynomialfeatures': {\n",
    "                                                               'interaction_only': False\n",
    "                                                              },\n",
    "                                        'robustscaler': {\n",
    "                                                        },\n",
    "                                        'randomforest': {\n",
    "                                                         'min_samples_split': 13,\n",
    "                                                         'min_samples_leaf': 5,\n",
    "                                                         'max_features': 0.25,\n",
    "                                                         'bootstrap': False\n",
    "                                                        }\n",
    "                                       },\n",
    "                         'requires_forecast': True,\n",
    "                         'description': '''scikit-learn RandomForestRegressor pipeline as recommended by TPOT.\n",
    "                                        Uses scikit-learn's PolynomialFeatures and robustscaler to pre-process\n",
    "                                        the data. Default parameters are as recommended by TPOT'''\n",
    "                         }\n",
    "multi_layer_perceptron = {\n",
    "                          'name': 'multi_layer_perceptron',\n",
    "                          'fun': 'mlpregressor',\n",
    "                          'parameter': {\n",
    "                                       },\n",
    "                          'requires_forecast': True,\n",
    "                          'description': '''scikit-learn MLPRegressor model with default parameters'''\n",
    "                         }\n",
    "tuned_mlp = {\n",
    "             'name': 'tuned_mlp',\n",
    "             'fun': 'mlpregressor',\n",
    "             'parameter': {\n",
    "                           'hidden_layer_sizes': 500,\n",
    "                           'alpha': 0.005050,\n",
    "                           'max_iter': 5000,\n",
    "                           'momentum': 0.1\n",
    "                          },\n",
    "             'requires_forecast': True,\n",
    "             'description': '''scikit-learn MLPRegressor model parameters tuned to optimize results on \n",
    "                            several meters (average score) in Camp Parks, 2020 data set'''\n",
    "            }\n",
    "\n",
    "tuned_Total_mlp = {\n",
    "                   'name': 'tuned_Total_mlp',\n",
    "                   'fun': 'mlpregressor',\n",
    "                   'parameter': {\n",
    "                                 'hidden_layer_sizes': 500,\n",
    "                                 'alpha': 0.01,\n",
    "                                 'max_iter': 5000,\n",
    "                                },\n",
    "                   'requires_forecast': True,\n",
    "                   'description': '''scikit-learn MLPRegressor model parameters tuned to optimize results on \n",
    "                                  Total Load in Camp Parks, 2020 data set'''\n",
    "                  }\n",
    "\n",
    "tuned_Fast_mlp = {\n",
    "                  'name': 'tuned_Fast_mlp',\n",
    "                  'fun': 'mlpregressor',\n",
    "                  'parameter': {\n",
    "                                'hidden_layer_sizes': 300,\n",
    "                                'alpha': 0.00505,\n",
    "                                'max_iter': 5000,\n",
    "                                'shuffle': True, \n",
    "                                'random_state': None, \n",
    "                                'tol': 0.0001, \n",
    "                                'momentum': 0.5\n",
    "                               },\n",
    "                  'requires_forecast': True,\n",
    "                  'description': '''scikit-learn MLPRegressor model parameters tuned to yield high performance \n",
    "                                 Total Load in Camp Parks, 2020 data set with fast simulation times. This is\n",
    "                                 the fastest parameter set with r2 score > (tuned mlp - 0.02)'''\n",
    "                 }\n",
    "\n",
    "random_forest = {\n",
    "                 'name': 'random_forest',\n",
    "                 'fun': 'randomforest',\n",
    "                 'parameter': {\n",
    "                               },\n",
    "                 'requires_forecast': True,\n",
    "                 'description': '''scikit-learn RandomForestRegressor model with default parameters'''\n",
    "                }\n",
    "\n",
    "extra_trees = {\n",
    "               'name': 'extra_trees',\n",
    "               'fun': 'extratrees',\n",
    "               'parameter': {\n",
    "                             },\n",
    "               'requires_forecast': True,\n",
    "               'description': '''scikit-learn ExtraTreesRegressor model with default parameters'''\n",
    "              }\n",
    "\n",
    "gradient_boosting = {\n",
    "                     'name': 'gradient_boosting',\n",
    "                     'fun': 'gradientboosting',\n",
    "                     'parameter': {\n",
    "                                   'targets': 'multiple',\n",
    "                                   'GBR': {\n",
    "                                           'max_depth': 3\n",
    "                                          },\n",
    "                                   'MultiOutputRegressor': {\n",
    "                                                            },\n",
    "                                  },\n",
    "                     'requires_forecast': True,\n",
    "                     'description': '''scikit-learn GradientBoostingRegressor model with\n",
    "                                    default parameters. Uses scikit-learn MultiOutputRegressor\n",
    "                                    to enable predicting multi-target problems. Cannot predict\n",
    "                                    single target problems.'''\n",
    "                    }\n",
    "\n",
    "sx_with_forecast = {\n",
    "                    'name': 'sarimax_with_forecast',\n",
    "                    'fun': 'sarimax_with_forecast',\n",
    "                    'parameter': {\n",
    "                                  'order_1': 2,\n",
    "                                  'order_2': 0,\n",
    "                                  'order_3': 0,\n",
    "                                  'seasonal_order_1': 0,\n",
    "                                  'seasonal_order_2': 1,\n",
    "                                  'seasonal_order_3': 1,\n",
    "                                  'seasonal_order_4': 4,\n",
    "                                  'trend': 'n',\n",
    "                                  'full_output': 1,\n",
    "                                  'callback': None,\n",
    "                                  'return_params': False,\n",
    "                                  'X_column_categories': ['temp_air', 'ghi', 'dhi', 'dni']\n",
    "                                 },\n",
    "                      'requires_forecast': False,\n",
    "                      'description': '''statsmodels SARIMAX seasonal forecasting algorithm using default parameters.'''\n",
    "                     }\n",
    "    \n",
    "todt = {\n",
    "        'name': 'todt',\n",
    "        'fun': 'time_of_day_temperature',\n",
    "        'parameter': {\n",
    "                      'LR': {\n",
    "                                          },\n",
    "                      'oat_col_identifier': 'temp_air',\n",
    "                     },\n",
    "        'requires_forecast': False,\n",
    "        'description': '''scikit-learn LinearRegression model with input data \n",
    "                       formatted to create individual regressions for each\n",
    "                       hour of the day.'''\n",
    "       }\n",
    "\n",
    "forecaster_list = [extra_trees_pipeline, random_forest_pipeline, multi_layer_perceptron, tuned_mlp, \n",
    "                   tuned_Total_mlp, tuned_Fast_mlp, random_forest, extra_trees, gradient_boosting, todt, sx_with_forecast]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import time\n",
    "    import math   \n",
    "    import inspect    \n",
    "    \n",
    "    # Read in example data set\n",
    "    cwd = os.getcwd()\n",
    "    path_data = os.path.join(cwd, '..', 'resources', 'data', 'forecaster_example_data.csv')\n",
    "    df = pd.read_csv(path_data, index_col = [0])\n",
    "    df.index = pd.to_datetime(df.index)       \n",
    "\n",
    "    # Split data set into X and y data sets\n",
    "    X = df[[col for col in df.columns if not 'y_' in col]]\n",
    "    y = df[[col for col in df.columns if 'y_' in col]]        \n",
    "    \n",
    "    # Create a dataframe to store the score when compared against test data and the computation time of each\n",
    "    # forecaster\n",
    "    forecaster_names = [forecaster['name'] for forecaster in forecaster_list]\n",
    "\n",
    "    result = pd.DataFrame(0, index = forecaster_names, \n",
    "                          columns = ['Test Score', 'RMSE', 'Computation Time (s)'])\n",
    "    \n",
    "    # Split X and y into train and test data sets. Set random_state to ensure repeatability\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)\n",
    "\n",
    "    # Many forecasters use stochastic noise in their process and yield a slightly different score each time. \n",
    "    # The test code performs x iterations and averages the test score and computation time across all iterations\n",
    "\n",
    "    iterations = 10\n",
    "    \n",
    "    # For each iteration as specified above\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # For each forecaster\n",
    "        for forecaster in forecaster_list:\n",
    "            fc_name = forecaster['name']\n",
    "            \n",
    "            model = getattr(sys.modules[__name__], forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            try:\n",
    "                result.loc[fc_name, 'Test Score'] += model.score(X_test, y_test)\n",
    "            \n",
    "                predict = model.predict(X_test)\n",
    "            \n",
    "                result.loc[fc_name, 'RMSE'] += np.sqrt(mean_squared_error(y_test, predict))\n",
    "\n",
    "            except Exception as e:\n",
    "                print('ERROR: {} - {}'.format(fc_name, e))\n",
    "            \n",
    "            # Calculate the computation time of the forecasterin pred\n",
    "            end = time.time()  \n",
    "            result.loc[fc_name, 'Computation Time (s)'] += end-start\n",
    "\n",
    "        print('Completed iteration {}'.format(i + 1))\n",
    "            \n",
    "    # Tabulate the average of the results for each forecaster\n",
    "    for fc_name in forecaster_names:\n",
    "    \n",
    "        result.loc[fc_name, 'Test Score'] = result.loc[fc_name, 'Test Score']/iterations\n",
    "        result.loc[fc_name, 'Computation Time (s)'] = result.loc[fc_name, 'Computation Time (s)']/iterations\n",
    "        result.loc[fc_name, 'RMSE'] = result.loc[fc_name, 'RMSE'] / iterations\n",
    "    \n",
    "    # Print results\n",
    "    print('Average score and computation time metrics over {} iterations'.format(iterations))\n",
    "    \n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c76c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "todt = {\n",
    "        'name': 'todt',\n",
    "        'fun': 'time_of_day_temperature',\n",
    "        'parameter': {\n",
    "                      'LR': {\n",
    "                                          },\n",
    "                      'oat_col_identifier': 'Tamb_forecast',\n",
    "                     },\n",
    "        'requires_forecast': False,\n",
    "        'description': '''scikit-learn LinearRegression model with input data \n",
    "                       formatted to create individual regressions for each\n",
    "                       hour of the day.'''\n",
    "       }\n",
    "\n",
    "sx_with_forecast = {\n",
    "                    'name': 'sarimax_with_forecast',\n",
    "                    'fun': 'sarimax_with_forecast',\n",
    "                    'parameter': {\n",
    "                                  'order_1': 2,\n",
    "                                  'order_2': 0,\n",
    "                                  'order_3': 0,\n",
    "                                  'seasonal_order_1': 0,\n",
    "                                  'seasonal_order_2': 1,\n",
    "                                  'seasonal_order_3': 1,\n",
    "                                  'seasonal_order_4': 4,\n",
    "                                  'trend': 'n',\n",
    "                                  'full_output': 1,\n",
    "                                  'callback': None,\n",
    "                                  'return_params': False,\n",
    "                                  'X_column_categories': ['Tamb_forecast', 'clear_sky_forecast', \n",
    "                                                          'cloud_cover_forecast', 'Ppv_dminus1_forecast']\n",
    "                                 },\n",
    "                    'requires_forecast': True,\n",
    "                    'description': '''statsmodels SARIMAX seasonal forecasting algorithm using default parameters.\n",
    "                                      This implementation is structured to utilize a weather forecast'''\n",
    "                   }\n",
    "\n",
    "forecaster_list = [extra_trees_pipeline, random_forest_pipeline, multi_layer_perceptron, tuned_mlp, \n",
    "                   tuned_Total_mlp, tuned_Fast_mlp, random_forest, extra_trees, gradient_boosting, todt, \n",
    "                   sx_with_forecast]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.exceptions import ConvergenceWarning\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import time\n",
    "    import math   \n",
    "    import inspect    \n",
    "    \n",
    "    # Read in example data set\n",
    "    cwd = os.getcwd()\n",
    "    path_data = os.path.join(cwd, '..', 'resources', 'data', 'forecaster_example_data_NN.csv')\n",
    "    df = pd.read_csv(path_data, index_col = [0])\n",
    "    df.index = pd.to_datetime(df.index)       \n",
    "\n",
    "    # Split data set into X and y data sets\n",
    "    X = df[[col for col in df.columns if not 'Ppv_forecast' in col]]\n",
    "    y = df[[col for col in df.columns if 'Ppv_forecast' in col]]        \n",
    "\n",
    "    # Create a dataframe to store the score when compared against test data and the computation time of each\n",
    "    # forecaster\n",
    "\n",
    "    forecaster_names = [forecaster['name'] for forecaster in forecaster_list]\n",
    "    \n",
    "    result = pd.DataFrame(0, index = forecaster_names, \n",
    "                          columns = ['Test Score', 'RMSE', 'Computation Time (s)'])\n",
    "    \n",
    "    # Split X and y into train and test data sets. Set random_state to ensure repeatability\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)\n",
    "\n",
    "    # Many forecasters use stochastic noise in their process and yield a slightly different score each time. \n",
    "    # The test code performs x iterations and averages the test score and computation time across all iterations\n",
    "\n",
    "    iterations = 10\n",
    "    \n",
    "    # For each iteration as specified above\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # For each forecaster\n",
    "        for forecaster in forecaster_list:\n",
    "            fc_name = forecaster['name']\n",
    "\n",
    "            model = getattr(sys.modules[__name__], forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            result.loc[fc_name, 'Test Score'] += model.score(X_test, y_test)\n",
    "            predict = model.predict(X_test)\n",
    "            result.loc[fc_name, 'RMSE'] += np.sqrt(mean_squared_error(y_test, predict))\n",
    "\n",
    "            # Calculate the computation time of the forecasterin pred\n",
    "            end = time.time()  \n",
    "            result.loc[fc_name, 'Computation Time (s)'] += end-start\n",
    "\n",
    "        print('Completed iteration {}'.format(i + 1))\n",
    "            \n",
    "    # Tabulate the average of the results for each forecaster\n",
    "    for fc_name in forecaster_names:\n",
    "    \n",
    "        result.loc[fc_name, 'Test Score'] = result.loc[fc_name, 'Test Score']/iterations\n",
    "        result.loc[fc_name, 'Computation Time (s)'] = result.loc[fc_name, 'Computation Time (s)']/iterations\n",
    "        result.loc[fc_name, 'RMSE'] = result.loc[fc_name, 'RMSE'] / iterations\n",
    "    \n",
    "    # Print results\n",
    "    print('Average score and computation time metrics over {} iterations'.format(iterations))\n",
    "    \n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee342f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots comparing the performance of the forecasters at 3 timestamps in the data set\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify needed inputs\n",
    "x = range(1, 24)\n",
    "\n",
    "index_percents = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Create the plot figure\n",
    "number_plots = len(index_percents)\n",
    "fig, axs = plt.subplots(number_plots, 1, figsize = (10, number_plots * 4), constrained_layout=True)\n",
    "datetimes = []\n",
    "    \n",
    "color = 0\n",
    "for forecaster in forecaster_list:\n",
    "    fc_name = forecaster['name']\n",
    "\n",
    "    model = getattr(sys.modules[__name__], forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "    if True:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    for i in index_percents:\n",
    "        row = index_percents.index(i)\n",
    "        index = int(i * len(X_test.index))\n",
    "        \n",
    "        forecast = X.iloc[index:index+1]\n",
    "        \n",
    "        predict = model.predict(forecast)\n",
    "\n",
    "        axs[row].plot(x, predict[0],\n",
    "                      label = fc_name, linestyle = 'dashed')\n",
    "    color += 1\n",
    "        \n",
    "for i in index_percents:\n",
    "    row = index_percents.index(i)\n",
    "    index = int(i * len(X_test.index))    \n",
    "    \n",
    "    axs[row].set(xlabel = ('Hour of Forecast [hr]'), ylabel = 'PV Power [W]',\n",
    "                 title = 'Prediction at {}'.format(str(y_test.index[index])))\n",
    "    y_real = y.iloc[index:index+1].values[0]\n",
    "    axs[row].plot(x, y_real, label = 'Test Data', linewidth = 5)    \n",
    "    axs[row].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49083c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = forecasters(forecaster_list)\n",
    "tuned.tune_hyperparameters(X, y, method = 'grid_small', n_jobs = 3)\n",
    "tuned.tuned_forecasters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
