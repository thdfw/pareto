{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a49a72",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b4a10",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2196a",
   "metadata": {},
   "source": [
    "The first step in testing the forecaster library is to import a data set. The forecaster library includes an example\n",
    "data set from a prior project on PV power production. The data set includes 24 hour forecasts for the following\n",
    "* Ambient temperature (Tamb_forecast_x)\n",
    "* Clear sky irradiation (clear_sky_forecast_x)\n",
    "* Cloud cover (cloud_cover_forecast_x)\n",
    "* PV production from the prior day (Ppv_dminus1_forecast_x)\n",
    "* Actual PV production (Ppv_forecast_x)\n",
    "\n",
    "where 'x' is the hour of the forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = os.path.join(cwd, '..', 'resources', 'data')\n",
    "\n",
    "data = pd.read_csv(os.path.join(folder, 'forecaster_example_data.csv'), index_col = 0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5151f5",
   "metadata": {},
   "source": [
    "The forecasters library is stored as fcLib. It contains a 'forecasters' class which facilitates using the forecasters in the library. fcLib contains a list (forecaster_list) of details about each forecaster and the default parameters.\n",
    "\n",
    "To initialize the forecasters library you must pass it a list of forecaster details. The previously specified forecaster_list provides those details from prior use in LBNL research projects.\n",
    "\n",
    "To create an instance of the forecaster library using the default models and see information about\n",
    "each forecaster you can use the following code. Note that the first lines add the src folder to the active python path, which may or may not be necessary depending on how your folders are arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(cwd, '..'))\n",
    "import fcLib\n",
    "\n",
    "library = fcLib.forecasters(fcLib.forecaster_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae82856",
   "metadata": {},
   "source": [
    "To better understand the forecasters available in the library you can print out each key.\n",
    "\n",
    "Notice that some of the forecasters are repeats (e.g. there are 4 versions of 'mlpregressor')\n",
    "and some of the forecasters include common keywords. The repeat forecasters use different \n",
    "data pre-processing and hyperparameters. The keywords are as follows:\n",
    "* pipeline: A scikit-learn pipeline with parameters as optimized by TPOT.\n",
    "* tuned: A regressor with hyperparameters tuned by LBNL to yield low RMSE for a specific target in a specific data set.\n",
    "* tuned-Total: The same as 'tuned', but matching multiple targets in a specific data set.\n",
    "* tuned-Fast: The same as tuned-Total, but designed to accept 10% higher RMSE in exchange for faster processing times.\n",
    "* no keyword: Uses default scikit-learn hyperparameters. Some models (e.g. time_of_week_temperature) have additional parameters on top of scikit-learn requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb1e2a",
   "metadata": {},
   "source": [
    "To better understand the forecasters available in the library you can print out each entry of forecaster_list. Each entry is a dictionary containing information about a specific forecaster. The entries in the dictionaries are:\n",
    "* fun: The name of the class in fcLib for that forecaster.\n",
    "* parameter: The default parameters for that forecaster. The included parameters are in some cases required to use the forecaster, and in other cases are overwriting scikit-learn defaults. If a parameter is not specified the forecaster uses the scikit-learn default.\n",
    "* description: A short description of the forecaster. More details are provided in the class description in fcLib.\n",
    "\n",
    "Notice that some of the forecasters are repeats (e.g. there are 4 versions of 'mlpregressor') and some of the forecasters include common keywords. The repeat forecasters use different data pre-processing and hyperparameters. The keywords are as follows:\n",
    "\n",
    "* pipeline: A scikit-learn pipeline with parameters as optimized by TPOT.\n",
    "* tuned: A regressor with hyperparameters tuned by LBNL to yield low RMSE for a specific target in a specific data set.\n",
    "* tuned-Total: The same as 'tuned', but matching multiple targets in a specific data set.\n",
    "* tuned-Fast: The same as tuned-Total, but designed to accept 10% higher RMSE in exchange for faster processing times.\n",
    "* no keyword: Uses default scikit-learn hyperparameters. Some models (e.g. time_of_week_temperature) have additional parameters on top of scikit-learn requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5957944",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in library.forecasters:\n",
    "    display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8d5fa",
   "metadata": {},
   "source": [
    "## Using the forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81721732",
   "metadata": {},
   "source": [
    "To train and test the forecasters on the data set you can simply pass the data set to the forecasters\n",
    "as if you were using a scikit-learn forecaster. We can calculate the rmse on the sample data set using\n",
    "the following steps.\n",
    "* Break the dataframe into y (real PV production, Ppv_forecast_1) and X (the weather parameters)\n",
    "* Split the dataframe into training and testing portions\n",
    "* Iterating through each model in the library\n",
    "* Fitting the model to the training data set\n",
    "* Predicting the PV production for all times in the testing data set\n",
    "* Calculating RMSE\n",
    "\n",
    "The sample data set contains 24 hours forecasts (x data) and PV power (y data) for each hour in the forecast. This means that we can treat the data set as a multi-target problem, with each forecaster predicting 24 hours of PV production at each timestamp. To do so we pass the full X and y data sets, informing the forecasters that they need to receive 24 hr forecasts and predict 24 hr production.\n",
    "\n",
    "The time_of_week_temperature model is specifically designed to predict building load using data sets with sub-hourly timesteps. Since the sample data set is for PV production using hourly data sets that forecaster does not perform well, and have been removed from the example code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into X and y\n",
    "X_columns = [col for col in data.columns if not 'Ppv_forecast' in col]\n",
    "X = data[X_columns]\n",
    "y_columns = [col for col in data.columns if 'Ppv_forecast' in col]\n",
    "y = data[y_columns]\n",
    "\n",
    "# Create training and testing data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 42)\n",
    "\n",
    "# Create a dataframe to store the rmse of each forecaster on this testing data\n",
    "forecaster_names = [forecaster['name'] for forecaster in library.forecasters]\n",
    "forecaster_names.remove('towt')\n",
    "scores = pd.DataFrame(index = forecaster_names, columns = ['RMSE'])\n",
    "\n",
    "# Iterate through each of the models\n",
    "for forecaster in library.forecasters:\n",
    "\n",
    "    if forecaster['name'] == 'towt':\n",
    "        continue\n",
    "    \n",
    "    # Fit the model to the training data and predict for the testing data\n",
    "    model = getattr(fcLib, forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the rmse and store it in the scores data frame\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predict))\n",
    "    scores.loc[forecaster['name'], 'RMSE'] = rmse\n",
    "\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20759b86",
   "metadata": {},
   "source": [
    "To predict the upcoming PV production for the following 24 hours you need to pass them a weather forecast in the same format as the training data. The following code shows an example that plots 24 hour predctions from each forecaster using the following steps:\n",
    "* Obtain the forecast by extracting data from a single row of the original data set\n",
    "* Create a date range and a y_real dataset for plotting purposes\n",
    "* Plot the real PV production data\n",
    "* Iterate through each forecaster\n",
    "* Predict the PV production for that forecaster given the current weather forecast\n",
    "* Plot the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaaf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 100 # Test on the 100th entry in the data set\n",
    "\n",
    "parameters = np.unique([col.rsplit('_', 1)[0] + '_1' for col in X.columns])\n",
    "\n",
    "forecast = pd.DataFrame(columns = X_columns)\n",
    "forecast.loc[X.index[ix]] = X.loc[X.index[ix]]\n",
    "y_real = pd.DataFrame(columns = y_columns)\n",
    "y_real.loc[y.index[ix]] = y.loc[y.index[ix]]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "\n",
    "x = range(1, 24)\n",
    "plt.plot(x, y_real.T, label = 'Measured', linewidth = 4)\n",
    "\n",
    "for forecaster in library.forecasters:\n",
    "    if forecaster['name'] == 'towt':\n",
    "        continue\n",
    "    \n",
    "    model = getattr(fcLib, forecaster['fun'])(**forecaster['parameter'])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predict = model.predict(forecast)\n",
    "    plt.plot(x, predict.T, label = forecaster['name'])\n",
    "        \n",
    "plt.xlabel('Datetime (MM-DD HH)')\n",
    "plt.ylabel('PV Production (W)')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea500074",
   "metadata": {},
   "source": [
    "## Tuning the forecasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48626b",
   "metadata": {},
   "source": [
    "fcLib.forecasters includes a function to tune the hyperparameters for several of the forecasters. That function can be called using the fcLib.forecasters.tune_hyperparameters() function. The inputs to tune_hyperparameters are:\n",
    "* X: The X data set to be used in hyperparameter tuning.\n",
    "* y: The y data set to be used in hyperparameter tuning.\n",
    "* method: The search method to be used. Options are 'grid_smal', 'grid_large' and 'randomized'.\n",
    "* cv: The number of folds to use when performing cross-validation.\n",
    "* n_forecasters: The number of tuned forecasters to include in the output list.\n",
    "* n_jobs: The number of cores to use when performing the hyperparameter tuning.\n",
    "* n_iter (optional): The number of iterations to use when performing randomized search.\n",
    "* random_state (optional): The random state to use when perfoming randomized search.\n",
    "\n",
    "The three search options are: 1) 'grid_small', 'grid_large', and 'randomized'. 'grid_small' and 'grid_large' both use scikit-learns GridSearch CV. 'randomized' uses scikit-learn's RandomizedSearchCV tool.\n",
    "\n",
    "Both 'grid' options perform a grid search over hyperparameter options specified for each forecaster. The hyperparameter options are stored in the 'search_parameters' attribute of the tuneable classes. That attribute can be edited as desired for specific applications. 'grid_small' is designed to complete in about 30 minutes when using 4 processes on a modern (2022) laptop. 'grid_large' searches over a larger parameter space, and is designed to complete in about 90 minutes.\n",
    "\n",
    "'randomized' performs a specified number of iterations for each forecaster, and calls randomization functions to determine the hyperparameters in each iteration. The size of the parameter space and processing time are both determined by the number of  iterations specified when calling the function.\n",
    "\n",
    "n_forecasters states the number of tuned forecasters to return in the output. tune_hyperparameters keeps the best performing n_forecasters models. Note that tune_hyperparameters also retains the non-tunable forecasters, so the final output will be larger than n_forecasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da753a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "library.tune_hyperparameters(X, y, method = 'grid_small', cv = 4, n_forecasters = 5, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d7bc8",
   "metadata": {},
   "source": [
    "Performing the grid search creates new attributes that store the forecasters with tuned parameters. The new attribute 'tuned_forecasters' provides a list of dictionaries with the name of the function, the parameters, and a quick description of the forecaster. 'tuned_models' stores a dictionary of the initialized models.\n",
    "\n",
    "Not all forecasters in the library are tunable. Models such as time_of_week_temperature don't have enough tunable parameters to include. The TPOT pipelines are considered optimized as they are, and are excluded. These forecasters are copied into the 'tuned_' attributes so they can still be used.\n",
    "\n",
    "Note that, since some forecasters in the library are duplicates with different parameters, there are fewer forecasters in the 'tuned_' sets than in the untuned sets. For instance, the four different implementations of MLPRegressor in the original set are reduced to a single instance of MLPRegrssor in the 'tuned_' set.\n",
    "\n",
    "If you want to see the details of the tuned forecasters you can print out the list as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in library.tuned_forecasters:\n",
    "    display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246eb78a",
   "metadata": {},
   "source": [
    "We can then plot the predicted PV production for the same weather forecast with the forecasters using the same methods as before. The only difference is that the code now uses each entry in 'tuned_models' instead of 'models'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23725e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 6))\n",
    "plt.plot(x, y_real.T, label = 'Measured', linewidth = 4)\n",
    "\n",
    "for forecaster in library.tuned_forecasters:\n",
    "    print(forecaster['parameter'])\n",
    "    model = getattr(fcLib, forecaster['fun'])(**forecaster['parameter'])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    predict = model.predict(forecast)\n",
    "    plt.plot(x, predict[0], label = forecaster['name'])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Datetime (MM-DD HH)')\n",
    "plt.ylabel('PV Production (W)')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
